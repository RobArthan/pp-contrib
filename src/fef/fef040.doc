=TEX
% TQtemplate.tex
\documentstyle[hol1,11pt,TQ]{article}
\def\Hide#1{}
\def\Bool{``$\it{:}bool\,$''}
\def\Note#1{{\small\bf[Note: #1]}}
\makeindex
\TPPproject{DRA FRONT END FILTER PROJECT}  %% Mandatory field
%\TPPvolume{}
%\TPPpart{}
\TPPtitle{Multi-level Formal Security Policy}  %% Mandatory field
\TPPref{DS/FMU/FEF/040}  %% Mandatory field
\def\SCCSversion{$Revision: 2.1 $
}
\TPPissue{\SCCSversion}  %% Mandatory field
\TPPdate{\FormatDate{$Date: 1994/04/08 15:38:13 $
}}  %% Mandatory field (with sensible default)
\TPPstatus{Approved}			%% Mandatory field
\TPPtype{Specification}
\TPPkeywords{}
\TPPauthor{R.~D.~Arthan & WIN01}  %% Mandatory field
%\TPPauthors{Name 1&location 1\\Name 2&location 2\\Name 3&location 3}
\TPPauthorisation{R.B.~Jones & HAT Manager}
\TPPabstract{A formulation of a multi-level formal security policy for the DRA front end filter project RSRE 1C/6130.}
%\TPPabstractB{}
%\TPPabstractC{}
%\TPPabstractD{}
%\TPPabstractE{}
%\TPPabstractF{}
\TPPdistribution{\parbox[t]{4.0in}{%
	HAT FEF File \\
	Simon Wiseman
}}
%\TPPclass{CLASSIFICATION}
\def\TPPheadlhs{Lemma 1}
%\def\TPPheadcentre{}
%def\TPPheadrhs{}
%\def\TPPfootlhs{}
%\def\TPPfootcentre{}
%\def\TPPfootrhs{}

\begin{document}
\TPPsetsizes
\makeTPPfrontpage

\vfill
\begin{centering}

%\bf Copyright \copyright\ : International Computers Ltd \number\year

\end{centering}

\newpage
\section {DOCUMENT CONTROL}
\subsection{Contents List}
\tableofcontents
\subsection{Document Cross References}
\bibliographystyle{fmu}
\bibliography{fmu,fef}

\subsection{Changes History}
\begin{description}
\item[Issue 1.1 ({\FormatDate{94/01/11}}) ] First draft. 
\item[Issue \SCCSversion ({\FormatDate{$Date: 1994/04/08 15:38:13 $
}}) ] Final approved version. 

\item[Issue 2.2] Removed dependency on ICL logo font
\end{description}

\subsection{Changes Forecast}
None.
\pagebreak
\section{GENERAL}
\subsection{Scope}

This document is a draft of constitutes part of deliverable D17 of phase 3 of the FEF project, as described in \cite{DS/FMU/FEF/039}.

\subsection{Introduction}

Phases 1 and 2 of the FEF project dealt exclusively with the formulation of the security policy defined in \cite{DS/FMU/FEF/003}.
In that formulation SSQL queries are treated as containing information at a single security clearance.
In phase 3, the intention is to generalise the policy to cater for queries which are structured objects containing components which may be at several different clearances.
This document gives a formal specification of a behavioural model of  systems
and a formal specification of a security policy allowing for such multi-level queries.

In fact, this ``security policy'' is just the policy of \cite{DS/FMU/FEF/003} adapted so that the notion of two inputs or outputs ``being the same at a given class'' is no longer fixed, but is supplied as a parameter.
This gives a simple framework in which some general reasoning about such policies can be carried out.
The approach also concentrates attention on the ``sameness'' structure on the inputs and outputs (or input and output sequences).
It is this structure which defines the meaning of assertions like ``such-and-such a component of the data has such-and-such a sensitivity''.

This document also contains the beginnings of a general analysis of information flows when a labelled component is extracted from an output sequence.
This was first considered as a possible approach to the result-labelling property.
However, further work on the specific details of SWORD (in \cite{DS/FMU/FEF/042}) suggests that more needs to be known about the actual intentions behind the component-labelling scheme than can be reflected easily in the general context of this document.
The material might be relevant in investigating the constraints a trusted client of SWORD would have to obey when carrying out the sorts of down-grading mentioned in \cite{securityprops}.

An index of the names used in the formal specification may be found in Section \ref{INDEX}. 
A listing of the theory $fef040$ created by processing this document using \Product{}
may be found at the end of this document.


\subsection{Setting Up}
The following \Product{} instructions set up the new theory $fef040$ and set the context 
for the proof tools.
The parent theory is the theory $fef003$ which contains the single level security policy and, in particular, the definition of the lattice of security classes.
=SML
open_theory"fef003";
(force_delete_theory "fef040" handle _ => ());
new_theory Û"fef040"İ;
new_parent Û"fef010"İ;
push_pc "hol";
=TEX

\section{MULTI-LEVEL SECURITY POLICY}

\subsection{Behavioural Models of Systems}

The ``generic security policy'' presented here would be instantiated as a property
on behavioural models of systems.
The inputs and outputs of systems will be thought of as structured objects whose components may be labelled with security classes.
For example, an input might be an abstract syntax tree for an SSQL query with the nodes labelled with classes.
An output might be an SSQL table with classes labelling the cells.


\subsection{Classes}
We use the lattice of security classes defined in \cite{DS/FMU/FEF/003} as the type $Class$ together with operations $dominates$, $lub$, etc.
We will need the notions of the down-set,
=INLINEFT
c%downarrow%
=TEX
, and the up-set,
=INLINEFT
c%uparrow%
=TEX
, of a class $c$.
We write these operators with postfix syntax:
=SML
declare_postfix(300, "%downarrow%");
declare_postfix(300, "%uparrow%");
=TEX
¹HOLCONST
Ü	Û$%downarrow%İ : Class ­ Class ğ
÷üüüüüüüüüüüüüü
Üµc·	c %downarrow% = { d | c dominates d }
°

¹HOLCONST
Ü	Û$%uparrow%İ : Class ­ Class ğ
÷üüüüüüüüüüüüüü
Üµc·	c %uparrow% = { d | d dominates c }
°

We may later need the idea of the ``orthogonal complement'' of a set $A$ of classes, which we shall write as
=INLINEFT
A ç%bottom%ê
=TEX
.
=INLINEFT
A ç%bottom%ê
=TEX
\ is to be the set of classes which are are not comparable with any element of $A$.
=SML
declare_postfix(300, "ç%bottom%ê");
=TEX
¹HOLCONST
Ü	Û$ç%bottom%êİ : Class ğ­ Class ğ
÷üüüüüüüüüüüüüü
ÜµA·	A ç%bottom%ê = { c | µd·d  A ´ ³ c dominates d ± ³ d dominates c }
°


\subsection{Sameness Structures}
In \cite{DS/FMU/FEF/003}, the security policy is expressed in terms of relations $same\_ins$, and $same\_outs$ parameterised by a security class.
In \cite{securityprops}, the non-interference property is expressed using a relation $identicalObjs$ also parameterised by a class.
\cite{securityprops} also uses a visibility predicate $visible$ again parameterised by a class.

To generalise these ideas from \cite{DS/FMU/FEF/003,securityprops}, it is convenient to define the notion of an equivalence relation,
(an equivalence relation being one which is reflexive, symmetric and transitive).


¹HOLCONST
Ü	ÛEquivalenceİ : ('a ª 'a) ğ
÷üüüüüüüüüüüüüü
Ü	Equivalence = Reflexive ¡ Symmetric ¡ Transitive
°

\Note{The above assumes that we are only concerned with equivalence relations on the entire type of objects.
This may mean that if the input and output objects have to satisfy some invariant, then it has to be captured in a type definition.}

In \cite{DS/FMU/FEF/003,securityprops}, two objects, $x$ and $y$, are take to be identical viewed from a class, $c$, if they become the same when components whose classification is not dominated by $c$ are ``purged''.
I.e., $x$ and $y$ are taken as the same at $c$ iff. they become identical when we treat components whose classification is not in
=INLINEFT
c %downarrow%
=TEX
\ as being equal. 
To tackle the result labelling property, it is useful to have available the analogous notion for any set of classes, not just down-sets.
To do this we introduce the idea of an {\em indexed equivalence relation}.
This is to be a function, $s$ associating with each set, $A$, of classes, an equivalence relation $s(A)$.
We require that $s$ be antimonotonic with respect to inclusion, i.e., the bigger the set $A$, the finer the equivalence relation $s(A)$:

¹HOLCONST
Ü	ÛIndexedEquivİ : (Class ğ ­ ('a ª 'a)) ğ
÷üüüüüüüüüüüüüü
Ü	IndexedEquiv =
Ü	{	s
Ü	|	(µA· s(A)  Equivalence)
Ü	±	(µA B· A € B ´ s(B) € s(A))}
°
(Here $s$ stands for ``same'' reflecting the terminology of \cite{DS/FMU/FEF/003}).

\Note{There are extra conditions one might choose to impose.
E.g. that $s\{\}$ is the complete relation and that $s\,Universe$ is the identity relation.
All the indexed equivalence one works with in practice satisfy
=INLINEFT
s(ŞU) = ¥(s(U))
=TEX
, for arbitrary families of sets $U$.
Thus $s(A)$ is determined by the values, $s\{c\}$, of $s$ on singleton sets.
However, the use of sets of classes seems to be technically convenient and allows one to consider various more or less pathological cases as well as well-behaved ones.}

Given a relation parameterised by individual classes we may lift it to an indexed relation.
In the next section, this allows us to relate the multi-level security policy with the single level one of \cite{DS/FMU/FEF/003}.
The lifting function is defined as follows:

¹HOLCONST
Ü	ÛLiftRelİ : (Class ­ ('a ª 'a)) ­ (Class ğ ­ ('a ª 'a))
÷üüüüüüüüüüüüüü
ÜµR·	LiftRel R = (ÌA·¥{ r | ¶c· c  A ± r = R c })
°

We will say that an indexed equivalence relation is {\em independent} if the following criterion holds:

¹HOLCONST
Ü	ÛIndependentİ : (Class ğ ­ ('a ª 'a)) ğ
÷üüüüüüüüüüüüüü
Ü	Independent =
Ü	{	s
Ü	|	µA x· (¶y· ³(x, y)  s(A)) ´ ¶z· ³(x, z)  s(A) ± (x, z)  s(A ç%bottom%ê)}
°

\Note{Above not used. Was intended to help with observations etc.}

\subsection{Security Policy} \label{CRITICAL}

The general multi-level security policy is parameterised by indexed equivalence relations on the inputs and outputs as defined in the previous section.
It is convenient to have the policy as a property of arbitrary functions rather than just of functions mapping input lists to output lists. 

¹HOLCONST
Ü	Ûx_ml_secureİ :	(Class ğ ­ ('I ª 'I)) ­
Ü			(Class ğ ­ ('O ª 'O)) ­
Ü			('I ­ 'O) ğ
÷üüüüüüüüüüüüüüüüüüüüüüü
Ü	µs‰I s‰O b
Ü	·	b  x_ml_secure s‰I s‰O 
Ü	¤		s‰I  IndexedEquiv
Ü		±	s‰O  IndexedEquiv
Ü		±	µc i‰1 i‰2·
Ü				(i‰1, i‰2)  s‰I (c %downarrow%)
Ü			´	(b i‰1, b i‰2)  s‰O (c %downarrow%)
°
More commonly in practice we are interested in the special case where the indexed equivalences are derived by lifting a relation parameterised by individual classes.
Thus we will more often use:

¹HOLCONST
Ü	Ûml_secureİ :	(Class ­ ('I ª 'I)) ­
Ü			(Class ­ ('O ª 'O)) ­
Ü			('I ­ 'O) ğ
÷üüüüüüüüüüüüüüüüüüüüüüü
Üµr‰I r‰O ·	ml_secure r‰I r‰O = x_ml_secure (LiftRel r‰I) (LiftRel r‰O)
°

The following conjecture, which is fairly straightforward to prove once a few lemmas about down-sets etc. have been established, shows that the above multi-level security policy does generalise the single level one of \cite{DS/FMU/FEF/003}.
=SML
val Ûconj_040_1İ = ¬
	µbm· bm  secure ¤ bm  ml_secure same_ins same_outs
®;
=TEX
\pagebreak
\section{COMPONENT EXTRACTION}

In this section certain ideas are explored which were intended originally to contribute to the formulation of the labelling property required for a multi-level secure relational database.
It appears from initial investigation that a good relationship between these ideas and the flow policy is not easy to establish, and it turned out that a labelling property thought to be appropriate can be defined without recourse to these ideas.
The section remains in the document {\it pro-tem}, pending consideration of whether this line can beneficially be further developed, but is not used as yet in subsequent documents. 

The general way we are modelling structured multi-level objects requires us to use indirect means to handle the idea of a component of an object labelled with a class.
We think of the component as being modelled by the function which maps an object to the class-value pair held in the component.
Because the class component is itself a potential source of information flows it will often be more convenient to think of such a function as a pair of functions, one to returning the class and the other the value.


Given an arbitrary function on a set endowed with an indexed equivalence relation, we consider the classes at or above which information has flowed into the result of applying the function.
This notion may be formalised as follows:

¹HOLCONST
Ü	ÛInfluencedİ: (Class ğ ­ ('a ª 'a)) ­ 'a ­ ('a ­ 'b) ­ Class ğ
÷üüüüüüüüüüüüüüüüüüüüüüü
Üµs x f·
Ü	Influenced s x f =
Ü	{ c | ¶y· (x, y)  s(~(c %uparrow%)) ± ³f(x) = f(y) }
°

(Here
=INLINEFT
~A
=TEX
\ is {\ProductHOL} notation for the complement of the set $A$.)

That is to say
=INLINEFT
Influenced s x f
=TEX
\ is the set of classes $c$ for which there is some state $y$, such that $f$ distinguishes $x$ and $y$, but $x$ and $y$ appear to be identical when viewed from any class which does not dominate $c$.

We model the process of examining a labelled component of an object in the output of a system by two functions, $C$ and $V$ say: $C$ computing the class; and $V$ computing the value.
The information-flow properties of such a pair will be considered relative to the clearance, $c$ say of the client to whom the result of the observation may be revealed.
We will call such a triple comprising $c$, $C$ and $V$ an {\em observation}:
=SML
declare_type_abbrev(Û"OBSERVATION"İ,["'a", "'b"],
	¬: Class ¸ ('a ­ Class) ¸ ('a ­ 'b)®);
=TEX
The labelled value produced when an object is observed is defined by the following function (which converts the pair of functions into a function returning pairs):

¹HOLCONST
Ü	ÛObservedValueİ : ('a, 'b) OBSERVATION ­ 'a ­ (Class ¸ 'b)
÷üüüüüüüüüüüüüüüüüüüüüüüüüüüüü
Üµc C V x·
Ü	ObservedValue (c, C, V) x = (C x, V x)
°

We can think of the labelled values resulting from observations as (single-level) classified objects using the following parameterised equivalence relation, (cf. the filtering operation which are performed on database cells in the single-level formulation of SWORD).

¹HOLCONST
Ü	ÛSameLabValİ : Class ­ (Class ¸ 'b) ª (Class ¸ 'b)
÷üüüüüüüüüüüüüüüüüüüüüüüüüüüüü
Üµc·	SameLabVal c =
Ü	{	((c‰1, v‰1), (c‰2, v‰2))
Ü	|	(c‰1 = c‰2)
Ü	±	(c dominates c‰1 ´ v‰1 = v‰2) }
°

We can now consider the question of when the process of making an observation is secure.
When a client makes an observation, we assume that some trusted part of the overall system will check the class which is returned and will withhold the value from clients who are not cleared to see it.
Thus the value may depend on information a client is not cleared to see, but this does not matter provided the class prevents the client from seeing the value.
However, since the class is itself intended to be part of what the client making the observation sees, the class must not depend on information the client is not allowed to know.
We will call an observation {\em bounded} if the following holds of it:

¹HOLCONST
Ü	ÛBoundedObsİ : (Class ğ ­ ('a ª 'a)) ­ ('a, 'b) OBSERVATION ğ
÷üüüüüüüüüüüüüüüüüüüüüüüüüüüüü
Üµs·	BoundedObs s =
Ü	{	(c, C, V) : ('a, 'b) OBSERVATION
Ü	|	µx·	Influenced s x C € c %downarrow%
Ü		±	Influenced s x V € (C x)%downarrow% }
°

That boundedness is necessary for an observation to be secure in a certain sense, is as asserted in the following conjecture:
=SML
val Ûconj_040_2İ = ¬
µs·	s  IndexedEquiv
´	µc C V·	ObservedValue (c, C, V)  x_ml_secure s (LiftRel SameLabVal)
		´	(c, C, V)  BoundedObs s
®;
=TEX
However, boundedness is not sufficient in general.
The problems arise with dependencies between the data which is visible at incomparable classes (e.g., arising from a state invariant linking values stored under incomparable classes).
E.g. assume the lattice of classes comprises $\bot$, $\top$ and three incomparable classes $I$, $J$, and $K$, as shown in the following diagram:

\def\IJKdiagram#1#2#3#4#5{%
\def\normalisebaselines{\baselineskip20pt \lineskip3pt \lineskiplimit3pt}
\matrix{%
	& 		& #2	& 		&		&\cr
	& \nearrow	& 	& \searrow	&		&\cr
#1	& \rightarrow	& #3	& \rightarrow	& #5		&\cr
	& \searrow	& 	& \nearrow	&		&\cr
	& 		& #4	& 		&		&\cr
}}

$$\IJKdiagram{\bot}{I}{J}{K}{\top}$$

As $c$ ranges over the possible classes, the sets
=INLINEFT
c%downarrow%
=TEX
\ which appear in the definition of $ml\_secure$ and the sets
=INLINEFT
~(c%uparrow%)
=TEX
\ which appear in the definition of $Influenced$
are as shown in the following table:

{\def\I{\bullet}\def\O{\circ}\def\IJK#1#2#3#4#5{\scriptsize$\IJKdiagram#1#2#3#4#5$}
\begin{tabular}{|l|c|c|c|c|c|c|}\hline
$c$	& $\bot$ & $I$ & $J$ & $K$ & $\top$ \\\hline
=INLINEFT
c%downarrow%
=TEX
	& \IJK{\I}{\O}{\O}{\O}{\O}	% bottom
	& \IJK{\I}{\I}{\O}{\O}{\O}	% I
	& \IJK{\I}{\O}{\I}{\O}{\O}	% J
	& \IJK{\I}{\O}{\O}{\I}{\O}	% K
	& \IJK{\I}{\I}{\I}{\I}{\I}	% top
\\\hline
=INLINEFT
~(c%uparrow%)
=TEX
	& \IJK{\O}{\O}{\O}{\O}{\O}	% bottom
	& \IJK{\I}{\O}{\I}{\I}{\O}	% I
	& \IJK{\I}{\I}{\O}{\I}{\O}	% J
	& \IJK{\I}{\I}{\I}{\O}{\O}	% K
	& \IJK{\I}{\I}{\I}{\I}{\O}	% top
\\\hline
\end{tabular}}

Now, let us assume that objects are triples of integers, $(x_I, x_J, x_K)$, and that the indexed equivalence, $s$, on these objects is obtained by classifying each component $x_c$ at $c$ (so that clients at class $\bot$ can see nothing, clients at classes $I$, $J$ and $K$ can see $x_I$, $x_J$ and $x_K$, respectively, and clients at class $\top$ can see everything).
Let us assume in addition that the objects are constrained to satisfy the invariant $x_I + x_J + x_K = 0$.
Consider any function $V$ with domain the set of triples satisfying this invariant.
Because of the invariant, the value of $V$ on any object $x$ is determined by the values of any two of the three components of $x$.
By reference to the table showing the values of
=INLINEFT
~(c%uparrow%)
=TEX
\ above, we find that for any state $x$, $Influenced\,s\,x\,V = \{\bot\}$.
However, it is clearly not secure to classify an arbitrary function on the set of objects as computing a value at class $\bot$.
E.g. the function $V_I$ which maps $(x_I, x_J, x_K)$ to $x_I$ must be classified at or above $I$ in order to be secure.


=IGN
val Ûconj_040_3İ = ¬
µs·		s  IndexedEquiv ± s  Independent
	´	µc C V·	(c, C, V)  BoundedObs s
		´	ObservedValue (c, C, V)  x_ml_secure s (LiftRel SameLabVal)
®;
=TEX
\section{CLOSING DOWN}
The following \Product{} instruction restores the previous proof context.
=SML
pop_pc();
=TEX
\newpage
\twocolumn[\section{INDEX} \label{INDEX}]
\small
\printindex

\end{document}
